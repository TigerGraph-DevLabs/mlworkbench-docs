{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3482340-811d-429a-ba1f-80baca631c7e",
   "metadata": {},
   "source": [
    "# Graph Convolutional Network for Link Prediction\n",
    "This notebook demonstrates the training of [Graph Convolutional Networks (GCN)](https://arxiv.org/pdf/1609.02907.pdf) for Link Prediction with TigerGraph. Pytorch Geometric's implementation of GCN is used here. We train the model on the Cora dataset from [PyG datasets](https://pytorch-geometric.readthedocs.io/en/latest/modules/datasets.html#torch_geometric.datasets.Planetoid) with TigerGraph as the data store. The dataset contains 2708 machine learning papers and 10556 citation links between the papers. Each publication in the dataset is described by a 0/1-valued word vector indicating the absence/presence of the corresponding word from a dictionary. The dictionary consists of 1433 unique words. Each paper is classified into one of seven classes based on the topic. The goal is to predict whether two papers are linked or not.\n",
    "\n",
    "The following libraries are required to run this notebook. Uncomment to install them if necessary. You might need to restart the kernel after installing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6af90ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install torch==1.12.0 --extra-index-url https://download.pytorch.org/whl/cpu\n",
    "#!pip install torch-scatter==2.0.9 torch-sparse==0.6.14 torch-cluster==1.6.0 torch-spline-conv==1.2.1 torch-geometric==2.0.4 -f https://data.pyg.org/whl/torch-1.12.0+cpu.html\n",
    "#!pip install pyTigerGraph[gds]\n",
    "#!pip install tensorboard # If you use tensorboard for visualization later"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6125c39e",
   "metadata": {},
   "source": [
    "**NOTE**: Currently, your database needs to be activated (only once) to enjoy all the functions provided by the ML Workbench. If you are using ML Workbench on Cloud, then the activator is included and you can run the cell below (uncomment first) to activate. For other versions of the Workbench, you can download the activator at https://act.tigergraphlabs.com. Detailed instructions are also included on that website. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ae732e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment below and fill out the necessary information. For detailed instructions, please see https://act.tigergraphlabs.com\n",
    "# !mlwb activate [database address] -u [username] -p [password] -s [secret]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5da30d",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "* [Data Processing](#data_processing)  \n",
    "* [Whole Graph Training](#train_whole)  \n",
    "* [Stochastic Batch Training](#train_subgraph) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d786d1fe-3758-4810-8c34-e66e59687a58",
   "metadata": {},
   "source": [
    "## Data Processing <a name=\"data_processing\"></a>\n",
    "\n",
    "Here we assume the dataset is already ingested into the TigerGraph database. If not, please refer to the  [data ingestion](https://github.com/TigerGraph-DevLabs/mlworkbench-docs/blob/main/tutorials/basics/0_data_ingestion.ipynb) tutorial first.\n",
    "\n",
    "For each edge, the original dataset include `is_train` and `is_val` attributes. You may add `is_test` if you want the train/validation/test splits. Otherwise, you can just use the edgeSplitter to get train/validation sets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81383884-2fb9-46f6-9ce6-ad227abf4e52",
   "metadata": {},
   "source": [
    "### Connect to TigerGraph\n",
    "\n",
    "The `TigerGraphConnection` class represents a connection to the TigerGraph database. Under the hood, it stores the necessary information to communicate with the database. It is able to perform quite a few database tasks. Please see its [documentation](https://docs.tigergraph.com/pytigergraph/current/intro/) for details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea45afd1-4fc3-4bc6-b739-2e89450df296",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyTigerGraph import TigerGraphConnection\n",
    "\n",
    "conn = TigerGraphConnection(\n",
    "    host=\"http://127.0.0.1\", # Change the address to your database server's\n",
    "    graphname=\"Cora\",\n",
    "    username=\"tigergraph\",\n",
    "    password=\"tigergraph\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e57c2c4",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">Uncomment cell below and run to get and set token if token authentication is enabled</span>. \n",
    "* This is required for all databases on tgcloud.\n",
    "* `<secret>` is your user secret. See https://docs.tigergraph.com/tigergraph-server/current/user-access/managing-credentials#_secrets for details.\n",
    "* If you don't know your secret, you can use `secret=conn.createSecret()` to create one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8055d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#conn.getToken(<secret>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3c94459-35aa-4e5b-a23a-cfc57b4ecac5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Paper': 2708}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn.getVertexCount('*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "196ba830-ed69-4b1a-b77d-9aaff54e6d65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Cite': 10556}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn.getEdgeCount('*')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a23f94b-12e9-43c0-8d9c-20046bf59e13",
   "metadata": {},
   "source": [
    "### Train/validation split\n",
    "\n",
    "Split the edges into 80% train and 20% validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93935b53-cbe4-4838-a570-55b750b1fff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing and optimizing queries. It might take a minute if this is the first time you use this loader.\n",
      "Query installation finished.\n",
      "CPU times: user 228 ms, sys: 39.5 ms, total: 268 ms\n",
      "Wall time: 49.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "splitter = conn.gds.edgeSplitter(is_train=0.8, is_val=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54abea3e-9f99-4d7a-be06-6aa6630552de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting edges...\n",
      "Edge split finished successfully.\n",
      "CPU times: user 4.73 ms, sys: 945 Âµs, total: 5.68 ms\n",
      "Wall time: 72.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "splitter.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63bc960-ec54-4755-b372-f40b367abce1",
   "metadata": {},
   "source": [
    "## Train on whole graph <a name=\"train_whole\"></a>\n",
    "\n",
    "Here, we use the full graph for link prediction. This will **NOT** work when the graph is very large. See the section of Stochastic Mini-Batch Training for real use. However, we still include this example for illustration purposes.\n",
    "\n",
    "We load the whole graph from TigerGraph which includes the feature and split results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182afd6a-a68d-4b28-8ac6-86e6a6b51e8f",
   "metadata": {},
   "source": [
    "### Construct graph loader and negative edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2544116b-4169-48ac-bd0f-049dfbcfc00d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing and optimizing queries. It might take a minute if this is the first time you use this loader.\n",
      "Query installation finished.\n"
     ]
    }
   ],
   "source": [
    "graph_loader = conn.gds.graphLoader(\n",
    "    num_batches=1,\n",
    "    v_in_feats = [\"x\"],\n",
    "    e_extra_feats=[\"is_train\",\"is_val\"],\n",
    "    output_format = \"PyG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "874be99d-9c9b-485c-ad75-7581132780a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = graph_loader.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29a1443b-e53d-4c0d-994d-b3e2a50e8a04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_index=[2, 10556], is_train=[10556], is_val=[10556], x=[2708, 1433])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bca4fdb7-94d1-4d46-a041-ad280efeb6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_edge_index = data.edge_index[:, data.is_train]\n",
    "val_edge_index = data.edge_index[:, data.is_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10410e24-e984-4c4d-9b54-61f66078f3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "neg_val_edge = torch.randint(0, data.x.shape[0], val_edge_index.size(), dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "abdd6e53-13e0-4299-8fee-b5ee9a90b2d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 8454]), torch.Size([2, 2102]), torch.Size([2, 2102]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_edge_index.shape, val_edge_index.shape, neg_val_edge.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef04bf96-ffc1-45ad-91f8-b490258668a3",
   "metadata": {},
   "source": [
    "### Construct GCN Model\n",
    "\n",
    "We use dot product to measure the similarity of two nodes in a decode function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d4bc349b-4830-4459-bf95-206cbe89d555",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers, dropout, **kwargs):\n",
    "        super(GCN, self).__init__()\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        self.convs.append(GCNConv(in_channels, hidden_channels))\n",
    "        for _ in range(num_layers - 2):\n",
    "            self.convs.append(GCNConv(hidden_channels, hidden_channels))\n",
    "        self.convs.append(GCNConv(hidden_channels, out_channels))\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for conv in self.convs:\n",
    "            conv.reset_parameters()\n",
    "\n",
    "    def forward(self, x, adj_t):\n",
    "        for i, conv in enumerate(self.convs[:-1]):\n",
    "            x = conv(x, adj_t)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.convs[-1](x, adj_t)\n",
    "        return x\n",
    "\n",
    "    def decode(self, z, pos_edge_index, neg_edge_index):\n",
    "        edge_index = torch.cat([pos_edge_index, neg_edge_index], dim=-1) # concatenate pos and neg edges\n",
    "        logits = (z[edge_index[0]] * z[edge_index[1]]).sum(dim=-1)  # dot product \n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a6bfba-3157-4330-ae6c-49e25a18491e",
   "metadata": {},
   "source": [
    "### Get binary labels for positive and negative edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8d5123bd-2ebc-43a6-a9b3-ac0d503c0f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_link_labels(pos_edge_index, neg_edge_index):\n",
    "    E = pos_edge_index.size(1) + neg_edge_index.size(1)\n",
    "    link_labels = torch.zeros(E, dtype=torch.float)\n",
    "    link_labels[:pos_edge_index.size(1)] = 1.\n",
    "    return link_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939e07f7-e6ae-4bea-ad82-3f549ddeba42",
   "metadata": {},
   "source": [
    "### Define Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a631ec03-1a9a-41a0-9734-ab7ff3dea269",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "hp = {\"hidden_dim\": 128, \"out_dim\": 64, \"num_layers\": 2,\n",
    "      \"dropout\": 0.6, \"lr\": 0.01, \"l2_penalty\": 5e-4}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db9abec-dc1c-401c-a3f0-7693c768ae3f",
   "metadata": {},
   "source": [
    "### Instantiate Model and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bcbc8fca-6eff-4238-928f-f51eb936496b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GCN(1433, hp[\"hidden_dim\"], hp[\"out_dim\"], hp[\"num_layers\"], hp[\"dropout\"])\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(), lr=hp[\"lr\"], weight_decay=hp[\"l2_penalty\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f0e9a355-e46b-4626-8a35-c5360dec07bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1.,  ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_labels = get_link_labels(val_edge_index, neg_val_edge)\n",
    "val_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a700bfa-253a-4868-877b-194598b30c07",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5cde228b-fd55-4116-88ad-dbcb787be5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4a894353-20f1-42d0-9d7e-6297a3cb4e4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, training loss: 0.6500421166419983, valid roc_auc_score: 0.8383314427562532\n",
      "Epoch: 1, training loss: 1.081446886062622, valid roc_auc_score: 0.812061323500522\n",
      "Epoch: 2, training loss: 1.1687164306640625, valid roc_auc_score: 0.7562404886470317\n",
      "Epoch: 3, training loss: 0.6771160364151001, valid roc_auc_score: 0.8145703742799436\n",
      "Epoch: 4, training loss: 0.6512936949729919, valid roc_auc_score: 0.8144599271592186\n",
      "Epoch: 5, training loss: 0.6514720320701599, valid roc_auc_score: 0.8029452490084655\n",
      "Epoch: 6, training loss: 0.6470925211906433, valid roc_auc_score: 0.7915663664979481\n",
      "Epoch: 7, training loss: 0.6444706916809082, valid roc_auc_score: 0.7924901163406516\n",
      "Epoch: 8, training loss: 0.6450539827346802, valid roc_auc_score: 0.8071957657108768\n",
      "Epoch: 9, training loss: 0.6447546482086182, valid roc_auc_score: 0.7999462022938599\n",
      "Epoch: 10, training loss: 0.6415925025939941, valid roc_auc_score: 0.7999011634065152\n",
      "Epoch: 11, training loss: 0.6420110464096069, valid roc_auc_score: 0.7940671563759222\n",
      "Epoch: 12, training loss: 0.6354835033416748, valid roc_auc_score: 0.8104411683494763\n",
      "Epoch: 13, training loss: 0.6298680305480957, valid roc_auc_score: 0.8130789986610549\n",
      "Epoch: 14, training loss: 0.617591917514801, valid roc_auc_score: 0.8237532149617826\n",
      "Epoch: 15, training loss: 0.6072716116905212, valid roc_auc_score: 0.845905105101299\n",
      "Epoch: 16, training loss: 0.5972340703010559, valid roc_auc_score: 0.8635679308637236\n",
      "Epoch: 17, training loss: 0.5859787464141846, valid roc_auc_score: 0.8642446458042314\n",
      "Epoch: 18, training loss: 0.569355845451355, valid roc_auc_score: 0.8725765004739267\n",
      "Epoch: 19, training loss: 0.559634268283844, valid roc_auc_score: 0.880606549333198\n",
      "Epoch: 20, training loss: 0.5440987348556519, valid roc_auc_score: 0.8762095996653996\n",
      "Epoch: 21, training loss: 0.5339546799659729, valid roc_auc_score: 0.884704295940344\n",
      "Epoch: 22, training loss: 0.5243106484413147, valid roc_auc_score: 0.883151133305148\n",
      "Epoch: 23, training loss: 0.513563871383667, valid roc_auc_score: 0.890787374807736\n",
      "Epoch: 24, training loss: 0.5073722004890442, valid roc_auc_score: 0.8890371953311649\n",
      "Epoch: 25, training loss: 0.5005218982696533, valid roc_auc_score: 0.895701366375732\n",
      "Epoch: 26, training loss: 0.4956182837486267, valid roc_auc_score: 0.9078041528117392\n",
      "Epoch: 27, training loss: 0.4941596984863281, valid roc_auc_score: 0.9012601609087806\n",
      "Epoch: 28, training loss: 0.4928068220615387, valid roc_auc_score: 0.8992277528265863\n",
      "Epoch: 29, training loss: 0.48640885949134827, valid roc_auc_score: 0.9051891814329338\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(30):\n",
    "    model.train()\n",
    "    neg_train_edge = torch.randint(0, data.x.shape[0], train_edge_index.size(), dtype=torch.long)\n",
    "    h = model(data.x.float(), train_edge_index)\n",
    "    logits = model.decode(h, train_edge_index, neg_train_edge)\n",
    "    labels = get_link_labels(train_edge_index, neg_train_edge)\n",
    "    loss = F.binary_cross_entropy_with_logits(logits, labels)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_logits = model.decode(h, val_edge_index, neg_val_edge)\n",
    "        val_logits = val_logits.sigmoid()\n",
    "        print('Epoch: {}, training loss: {}, valid roc_auc_score: {}'.format(epoch, loss.item(), roc_auc_score(val_labels, val_logits)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad2acb3-f850-42aa-8333-ab82733d72bb",
   "metadata": {},
   "source": [
    "## Stochastic Batch Training <a name=\"train_subgraph\"></a>\n",
    "\n",
    "For stochastic batch training, we split the training edges into batches. At each specific batch, to do the link prediction, we need to know the neighbor graphs for each pair of nodes that has an edge.\n",
    "\n",
    "We use the edgeNeighborLoader, which can load the neighbors of the pair nodes of an edge and has the same parameters as neighborLoader(). The result of a batch is, for example,\n",
    "\n",
    "`Data(edge_index=[2, 6917], is_train=[6917], is_val=[6917], is_test=[6917], is_seed=[6917], x=[2188, 1433], y=[2188])`\n",
    "\n",
    "where `is_seed` indicates whether each edge is a seed edge or not\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3a41d8aa-55f7-4e31-a2b0-3edcfc1cd73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "hp = {\"hidden_dim\": 128, \"out_dim\": 64, \"num_layers\": 2,\n",
    "      \"dropout\": 0.6, \"lr\": 0.01, \"l2_penalty\": 5e-4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "31f89253-93ca-479b-8d1c-5a06bef9aaa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GCN(1433, hp[\"hidden_dim\"], hp[\"out_dim\"], hp[\"num_layers\"], hp[\"dropout\"])\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(), lr=hp[\"lr\"], weight_decay=hp[\"l2_penalty\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74bb697c-7355-46e0-b6ab-f54750eedb85",
   "metadata": {},
   "source": [
    "### Construct the edge_neighbor_loader for train/val edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c2711014-81ce-4ff4-8959-3e251b7bf394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing and optimizing queries. It might take a minute if this is the first time you use this loader.\n",
      "Query installation finished.\n"
     ]
    }
   ],
   "source": [
    "train_edge_neighbor_loader = conn.gds.edgeNeighborLoader(\n",
    "    v_in_feats=[\"x\"],\n",
    "    v_out_labels=[\"y\"],\n",
    "    num_batches=5,\n",
    "    e_extra_feats=[\"is_train\",\"is_val\"],\n",
    "    output_format=\"PyG\",\n",
    "    num_neighbors=10,\n",
    "    num_hops=2,\n",
    "    filter_by=\"is_train\",\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7e02ab37-dcf2-4681-971d-04a2ae8ed0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_edge_neighbor_loader = conn.gds.edgeNeighborLoader(\n",
    "    v_in_feats=[\"x\"],\n",
    "    v_out_labels=[\"y\"],\n",
    "    num_batches=5,\n",
    "    e_extra_feats=[\"is_train\",\"is_val\"],\n",
    "    output_format=\"PyG\",\n",
    "    num_neighbors=10,\n",
    "    num_hops=2,\n",
    "    filter_by=\"is_val\",\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd6ab8a-a266-48f5-97ae-38aab5a2bab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, training loss: 3.904411494731903, valid roc_auc_score: 0.8237392959086584\n",
      "Epoch: 1, training loss: 3.1914963126182556, valid roc_auc_score: 0.8996884395360859\n",
      "Epoch: 2, training loss: 2.9413991570472717, valid roc_auc_score: 0.9132218330419763\n",
      "Epoch: 3, training loss: 2.5968366861343384, valid roc_auc_score: 0.9252033087060395\n",
      "Epoch: 4, training loss: 2.427817314863205, valid roc_auc_score: 0.9299228861824314\n",
      "Epoch: 5, training loss: 2.3323494493961334, valid roc_auc_score: 0.9444609410999989\n",
      "Epoch: 6, training loss: 2.3284645080566406, valid roc_auc_score: 0.9524406324093495\n",
      "Epoch: 7, training loss: 2.2777881622314453, valid roc_auc_score: 0.9523057420733823\n",
      "Epoch: 8, training loss: 2.2383748292922974, valid roc_auc_score: 0.9618454989629739\n",
      "Epoch: 9, training loss: 2.2285644710063934, valid roc_auc_score: 0.9601150098542369\n",
      "Epoch: 10, training loss: 2.2250851690769196, valid roc_auc_score: 0.9643573788182338\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for bid, batch in enumerate(train_edge_neighbor_loader):\n",
    "        # get the training edges and negative edges sampled in the same batch\n",
    "        train_edges = batch.edge_index[:, batch.is_seed]\n",
    "        neg_train_edges = torch.randint(0, batch.x.shape[0], train_edges.size(), dtype=torch.long)\n",
    "        # The graph only include the edges whose is_train is True\n",
    "        train_graph_edges = batch.edge_index[:, batch.is_train]\n",
    "        h = model(batch.x.float(), train_graph_edges)\n",
    "        logits = model.decode(h, train_edges, neg_train_edges)\n",
    "        labels = get_link_labels(train_edges, neg_train_edges)\n",
    "        loss = F.binary_cross_entropy_with_logits(logits, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    model.eval()\n",
    "    all_labels = []\n",
    "    all_logits = []\n",
    "    for batch in val_edge_neighbor_loader:\n",
    "        val_edges = batch.edge_index[:, batch.is_seed]\n",
    "        neg_val_edges = torch.randint(0, batch.x.shape[0], val_edges.size(), dtype=torch.long)\n",
    "        # Need to use the train edge for GCN\n",
    "        val_graph_edges = batch.edge_index[:, batch.is_train]\n",
    "        with torch.no_grad():\n",
    "            h = model(batch.x.float(), val_graph_edges)\n",
    "            logits = model.decode(h, val_edges, neg_val_edges)\n",
    "            labels = get_link_labels(val_edges, neg_val_edges)\n",
    "            logits = logits.sigmoid()\n",
    "            all_labels.extend(labels)\n",
    "            all_logits.extend(logits)\n",
    "    print('Epoch: {}, training loss: {}, valid roc_auc_score: {}'.format(epoch, total_loss, roc_auc_score(all_labels, all_logits)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca8f8df-e966-4c91-845e-03c2161ad8fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "fc5eadac82f5951e7eb836bb06f3c9df8e6d1eda5537a95773af6c6ed24cb2d0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
